{
  
    
        "post0": {
            "title": "Working with string methods in pandas",
            "content": "One of the most useful features of pandas is its ability to take a bit of code that looks like it operates on a single bit of data, and have it operate on a whole bunch of different values. To see an example, let&#39;s load a dataset that shows fuel efficiency for different car models: . import pandas as pd pd.options.display.max_rows = 10 df = pd.read_csv( &quot;https://raw.githubusercontent.com/mwaskom/seaborn-data/master/mpg.csv&quot; ) df . mpg cylinders displacement horsepower weight acceleration model_year origin name . 0 18.0 | 8 | 307.0 | 130.0 | 3504 | 12.0 | 70 | usa | chevrolet chevelle malibu | . 1 15.0 | 8 | 350.0 | 165.0 | 3693 | 11.5 | 70 | usa | buick skylark 320 | . 2 18.0 | 8 | 318.0 | 150.0 | 3436 | 11.0 | 70 | usa | plymouth satellite | . 3 16.0 | 8 | 304.0 | 150.0 | 3433 | 12.0 | 70 | usa | amc rebel sst | . 4 17.0 | 8 | 302.0 | 140.0 | 3449 | 10.5 | 70 | usa | ford torino | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 393 27.0 | 4 | 140.0 | 86.0 | 2790 | 15.6 | 82 | usa | ford mustang gl | . 394 44.0 | 4 | 97.0 | 52.0 | 2130 | 24.6 | 82 | europe | vw pickup | . 395 32.0 | 4 | 135.0 | 84.0 | 2295 | 11.6 | 82 | usa | dodge rampage | . 396 28.0 | 4 | 120.0 | 79.0 | 2625 | 18.6 | 82 | usa | ford ranger | . 397 31.0 | 4 | 119.0 | 82.0 | 2720 | 19.4 | 82 | usa | chevy s-10 | . 398 rows × 9 columns . Each row is a car, and for each car we have miles per gallon (mpg), plus a bunch of information about the engine and car, and finally the name. Say we want to convert the horsepower column into Kilowatts (kW). A quick trip to Google shows that one horsepower equals 0.7457 kW, so we might just iterate over the values and convert them like this: . kilowatts = [] for horsepower in df[&#39;horsepower&#39;]: kilowatts.append(horsepower * 0.7457) kilowatts[:10] . [96.941, 123.04050000000001, 111.855, 111.855, 104.39800000000001, 147.64860000000002, 164.054, 160.3255, 167.7825, 141.683] . However, the magic of pandas allows us to do this instead: . df[&#39;horsepower&#39;] * 0.7457 . 0 96.9410 1 123.0405 2 111.8550 3 111.8550 4 104.3980 ... 393 64.1302 394 38.7764 395 62.6388 396 58.9103 397 61.1474 Name: horsepower, Length: 398, dtype: float64 . We just write the expression as if we were trying to convert a single number, and pandas takes care of applying it to the whole series. This is called vectorization, and it&#39;s generally faster and more convenient than writing for loops. . However, we often run into problems when we try to use the same technique with text data. Let&#39;s get a list of the manufacturers for each car, which we can do just by getting the word before the first space in the name field. . First we&#39;ll use a loop: . manufacturers = [] for model in df[&#39;name&#39;]: manufacturers.append(model.split(&#39; &#39;)[0]) manufacturers[:10] . [&#39;chevrolet&#39;, &#39;buick&#39;, &#39;plymouth&#39;, &#39;amc&#39;, &#39;ford&#39;, &#39;ford&#39;, &#39;chevrolet&#39;, &#39;plymouth&#39;, &#39;pontiac&#39;, &#39;amc&#39;] . So far so good. Now, can we use the same trick as we did earlier and write the expression as if we&#39;re calculating it for a single value? . df[&#39;name&#39;].split(&#39; &#39;)[0] . AttributeError Traceback (most recent call last) &lt;ipython-input-5-453444d0ed9d&gt; in &lt;module&gt; -&gt; 1 df[&#39;name&#39;].split(&#39; &#39;)[0] ~/.virtualenvs/drawingfromdata/lib/python3.8/site-packages/pandas/core/generic.py in __getattr__(self, name) 5128 if self._info_axis._can_hold_identifiers_and_holds_name(name): 5129 return self[name] -&gt; 5130 return object.__getattribute__(self, name) 5131 5132 def __setattr__(self, name: str, value) -&gt; None: AttributeError: &#39;Series&#39; object has no attribute &#39;split&#39; . The magic doesn&#39;t work. To put it in simple terms, a pandas Series object &quot;knows&quot; about the * operator, but it doesn&#39;t know anything about split(). If we think about it, we can see why this must be the case. A Series object has to be able to hold either numbers or text, so it doesn&#39;t make sense for it to have methods like split() that only work on text. . One way round this is to switch to apply(), which lets us run arbitrary code on values in a series. We can write a function that takes a single name and returns the manufacturer: . def get_manufacturer(name): return name.split(&#39; &#39;)[0] . Then apply it to the name column: . df[&#39;name&#39;].apply(get_manufacturer) . 0 chevrolet 1 buick 2 plymouth 3 amc 4 ford ... 393 ford 394 vw 395 dodge 396 ford 397 chevy Name: name, Length: 398, dtype: object . But a better way is to use the series str attribute. This attribute has nearly all of the string methods that we might be used to, plus a bunch more functionality specific to pandas. Let&#39;s start with a simpler example - say we want to change all the names to upper case. Here it is with apply(): . df[&#39;name&#39;].apply(str.upper) . 0 CHEVROLET CHEVELLE MALIBU 1 BUICK SKYLARK 320 2 PLYMOUTH SATELLITE 3 AMC REBEL SST 4 FORD TORINO ... 393 FORD MUSTANG GL 394 VW PICKUP 395 DODGE RAMPAGE 396 FORD RANGER 397 CHEVY S-10 Name: name, Length: 398, dtype: object . And here is is using the str attribute: . df[&#39;name&#39;].str.upper() . 0 CHEVROLET CHEVELLE MALIBU 1 BUICK SKYLARK 320 2 PLYMOUTH SATELLITE 3 AMC REBEL SST 4 FORD TORINO ... 393 FORD MUSTANG GL 394 VW PICKUP 395 DODGE RAMPAGE 396 FORD RANGER 397 CHEVY S-10 Name: name, Length: 398, dtype: object . Going back to our original problem, we can split the name into a list of strings like this: . df[&#39;name&#39;].str.split(&#39; &#39;) . 0 [chevrolet, chevelle, malibu] 1 [buick, skylark, 320] 2 [plymouth, satellite] 3 [amc, rebel, sst] 4 [ford, torino] ... 393 [ford, mustang, gl] 394 [vw, pickup] 395 [dodge, rampage] 396 [ford, ranger] 397 [chevy, s-10] Name: name, Length: 398, dtype: object . Now there&#39;s one final complication before we can get just the first word - the result of the expression above is itself a series. So we have to access its str attribute again before we can use square brackets to get just the first word: . df[&#39;name&#39;].str.split(&#39; &#39;).str[0] . 0 chevrolet 1 buick 2 plymouth 3 amc 4 ford ... 393 ford 394 vw 395 dodge 396 ford 397 chevy Name: name, Length: 398, dtype: object . Now we have a series which contains the data we want. At this point we could store it in a new column: . df[&#39;manufacturer&#39;] = df[&#39;name&#39;].str.split(&#39; &#39;).str[0] df . mpg cylinders displacement horsepower weight acceleration model_year origin name manufacturer . 0 18.0 | 8 | 307.0 | 130.0 | 3504 | 12.0 | 70 | usa | chevrolet chevelle malibu | chevrolet | . 1 15.0 | 8 | 350.0 | 165.0 | 3693 | 11.5 | 70 | usa | buick skylark 320 | buick | . 2 18.0 | 8 | 318.0 | 150.0 | 3436 | 11.0 | 70 | usa | plymouth satellite | plymouth | . 3 16.0 | 8 | 304.0 | 150.0 | 3433 | 12.0 | 70 | usa | amc rebel sst | amc | . 4 17.0 | 8 | 302.0 | 140.0 | 3449 | 10.5 | 70 | usa | ford torino | ford | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 393 27.0 | 4 | 140.0 | 86.0 | 2790 | 15.6 | 82 | usa | ford mustang gl | ford | . 394 44.0 | 4 | 97.0 | 52.0 | 2130 | 24.6 | 82 | europe | vw pickup | vw | . 395 32.0 | 4 | 135.0 | 84.0 | 2295 | 11.6 | 82 | usa | dodge rampage | dodge | . 396 28.0 | 4 | 120.0 | 79.0 | 2625 | 18.6 | 82 | usa | ford ranger | ford | . 397 31.0 | 4 | 119.0 | 82.0 | 2720 | 19.4 | 82 | usa | chevy s-10 | chevy | . 398 rows × 10 columns . Or do any other type of series processing: . df[&#39;name&#39;].str.split(&#39; &#39;).str[0].value_counts() . ford 51 chevrolet 43 plymouth 31 amc 28 dodge 28 .. hi 1 chevroelt 1 nissan 1 vokswagen 1 toyouta 1 Name: name, Length: 37, dtype: int64 . This technique is also very useful for filtering. Say we want to find just the cars made by Ford. We can use the startswith method of the str attribute to get a series of boolean values: . df[&#39;name&#39;].str.startswith(&#39;ford&#39;) . 0 False 1 False 2 False 3 False 4 True ... 393 True 394 False 395 False 396 True 397 False Name: name, Length: 398, dtype: bool . Which we can then use as a filter mask: . df[df[&#39;name&#39;].str.startswith(&#39;ford&#39;)] . mpg cylinders displacement horsepower weight acceleration model_year origin name manufacturer . 4 17.0 | 8 | 302.0 | 140.0 | 3449 | 10.5 | 70 | usa | ford torino | ford | . 5 15.0 | 8 | 429.0 | 198.0 | 4341 | 10.0 | 70 | usa | ford galaxie 500 | ford | . 17 21.0 | 6 | 200.0 | 85.0 | 2587 | 16.0 | 70 | usa | ford maverick | ford | . 25 10.0 | 8 | 360.0 | 215.0 | 4615 | 14.0 | 70 | usa | ford f250 | ford | . 32 25.0 | 4 | 98.0 | NaN | 2046 | 19.0 | 71 | usa | ford pinto | ford | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 365 20.2 | 6 | 200.0 | 88.0 | 3060 | 17.1 | 81 | usa | ford granada gl | ford | . 373 24.0 | 4 | 140.0 | 92.0 | 2865 | 16.4 | 82 | usa | ford fairmont futura | ford | . 389 22.0 | 6 | 232.0 | 112.0 | 2835 | 14.7 | 82 | usa | ford granada l | ford | . 393 27.0 | 4 | 140.0 | 86.0 | 2790 | 15.6 | 82 | usa | ford mustang gl | ford | . 396 28.0 | 4 | 120.0 | 79.0 | 2625 | 18.6 | 82 | usa | ford ranger | ford | . 51 rows × 10 columns . There are many useful methods hiding in the str attribute. Let&#39;s find all the cars with names longer than 30 characters, which we can do with the len() method: . long_name_cars = df[df[&#39;name&#39;].str.len() &gt; 30] long_name_cars . mpg cylinders displacement horsepower weight acceleration model_year origin name manufacturer . 73 13.0 | 8 | 307.0 | 130.0 | 4098 | 14.0 | 72 | usa | chevrolet chevelle concours (sw) | chevrolet | . 133 16.0 | 6 | 250.0 | 100.0 | 3781 | 17.0 | 74 | usa | chevrolet chevelle malibu classic | chevrolet | . 187 17.5 | 8 | 305.0 | 140.0 | 4215 | 13.0 | 76 | usa | chevrolet chevelle malibu classic | chevrolet | . 244 43.1 | 4 | 90.0 | 48.0 | 1985 | 21.5 | 78 | europe | volkswagen rabbit custom diesel | volkswagen | . 249 19.9 | 8 | 260.0 | 110.0 | 3365 | 15.5 | 78 | usa | oldsmobile cutlass salon brougham | oldsmobile | . 263 17.7 | 6 | 231.0 | 165.0 | 3445 | 13.4 | 78 | usa | buick regal sport coupe (turbo) | buick | . 292 18.5 | 8 | 360.0 | 150.0 | 3940 | 13.0 | 79 | usa | chrysler lebaron town @ country (sw) | chrysler | . 300 23.9 | 8 | 260.0 | 90.0 | 3420 | 22.2 | 79 | usa | oldsmobile cutlass salon brougham | oldsmobile | . 387 38.0 | 6 | 262.0 | 85.0 | 3015 | 17.0 | 82 | usa | oldsmobile cutlass ciera (diesel) | oldsmobile | . Here&#39;s a common annoyance when making charts with long axis labels: . import matplotlib.pyplot as plt plt.figure(figsize=(8,8)) long_name_cars.set_index(&#39;name&#39;)[&#39;horsepower&#39;].plot(kind=&#39;barh&#39;) None . The long labels take up a bunch of space on the left hand side of the chart. We can fix this by using the .wrap() method to split the names over multiple lines: . plt.figure(figsize=(8,8)) long_name_cars[&#39;display_name&#39;] = long_name_cars[&#39;name&#39;].str.wrap(15) long_name_cars.set_index(&#39;display_name&#39;)[&#39;horsepower&#39;].plot(kind=&#39;barh&#39;) None . One last example: a bunch of the car names end with the string &quot;(sw)&quot;. Let&#39;s find them: . df[df[&#39;name&#39;].str.endswith(&#39;(sw)&#39;)] . mpg cylinders displacement horsepower weight acceleration model_year origin name manufacturer . 13 14.0 | 8 | 455.0 | 225.0 | 3086 | 10.0 | 70 | usa | buick estate wagon (sw) | buick | . 42 12.0 | 8 | 383.0 | 180.0 | 4955 | 11.5 | 71 | usa | dodge monaco (sw) | dodge | . 43 13.0 | 8 | 400.0 | 170.0 | 4746 | 12.0 | 71 | usa | ford country squire (sw) | ford | . 44 13.0 | 8 | 400.0 | 175.0 | 5140 | 12.0 | 71 | usa | pontiac safari (sw) | pontiac | . 45 18.0 | 6 | 258.0 | 110.0 | 2962 | 13.5 | 71 | usa | amc hornet sportabout (sw) | amc | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 289 16.9 | 8 | 350.0 | 155.0 | 4360 | 14.9 | 79 | usa | buick estate wagon (sw) | buick | . 290 15.5 | 8 | 351.0 | 142.0 | 4054 | 14.3 | 79 | usa | ford country squire (sw) | ford | . 291 19.2 | 8 | 267.0 | 125.0 | 3605 | 15.0 | 79 | usa | chevrolet malibu classic (sw) | chevrolet | . 292 18.5 | 8 | 360.0 | 150.0 | 3940 | 13.0 | 79 | usa | chrysler lebaron town @ country (sw) | chrysler | . 340 25.8 | 4 | 156.0 | 92.0 | 2620 | 14.4 | 81 | usa | dodge aries wagon (sw) | dodge | . 28 rows × 10 columns . The &quot;sw&quot; stands for &quot;Station Wagon&quot;. Let&#39;s replace the abbreviation with the full name: . df[&#39;name&#39;] = df[&#39;name&#39;].str.replace(&quot; (sw )&quot;, &quot;(Station Wagon)&quot;) df[40:50] . mpg cylinders displacement horsepower weight acceleration model_year origin name manufacturer . 40 14.0 | 8 | 351.0 | 153.0 | 4154 | 13.5 | 71 | usa | ford galaxie 500 | ford | . 41 14.0 | 8 | 318.0 | 150.0 | 4096 | 13.0 | 71 | usa | plymouth fury iii | plymouth | . 42 12.0 | 8 | 383.0 | 180.0 | 4955 | 11.5 | 71 | usa | dodge monaco (Station Wagon) | dodge | . 43 13.0 | 8 | 400.0 | 170.0 | 4746 | 12.0 | 71 | usa | ford country squire (Station Wagon) | ford | . 44 13.0 | 8 | 400.0 | 175.0 | 5140 | 12.0 | 71 | usa | pontiac safari (Station Wagon) | pontiac | . 45 18.0 | 6 | 258.0 | 110.0 | 2962 | 13.5 | 71 | usa | amc hornet sportabout (Station Wagon) | amc | . 46 22.0 | 4 | 140.0 | 72.0 | 2408 | 19.0 | 71 | usa | chevrolet vega (Station Wagon) | chevrolet | . 47 19.0 | 6 | 250.0 | 100.0 | 3282 | 15.0 | 71 | usa | pontiac firebird | pontiac | . 48 18.0 | 6 | 250.0 | 88.0 | 3139 | 14.5 | 71 | usa | ford mustang | ford | . 49 23.0 | 4 | 122.0 | 86.0 | 2220 | 14.0 | 71 | usa | mercury capri 2000 | mercury | . Notice that we have to escape the parentheses in the &quot;(sw)&quot; string, as the replace() method works on regular expressions. . There are many other useful string processing methods in the pandas str attribute. The documentation page has a bunch of examples, and a method summary at the end. So before you set out to process strings either by writing a loop, or by using apply(), check to see if there&#39;s a method there that will do what you want! .",
            "url": "https://mojones.github.io/dfd_jupyter_test/pandas/strings/2020/10/26/working-with-pandas-string-methods.html",
            "relUrl": "/pandas/strings/2020/10/26/working-with-pandas-string-methods.html",
            "date": " • Oct 26, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Setting the size of a figure in matplotlib and seaborn",
            "content": "TL;DR . if you&#39;re using plot() on a pandas Series or Dataframe, use the figsize keyword | if you&#39;re using matplotlib directly, use matplotlib.pyplot.figure with the figsize keyword | if you&#39;re using a seaborn function that draws a single plot, use matplotlib.pyplot.figure with the figsize keyword | if you&#39;re using a seaborn function that draws multiple plots, use the height and aspect keyword arguments | . Introduction . Setting figure sizes is one of those things that feels like it should be very straightforward. However, it still manages to show up on the first page of stackoverflow questions for both matplotlib and seaborn. Part of the confusion arises because there are so many ways to do the same thing - this highly upvoted question has six suggested solutions: . manually create an Axes object with the desired size | pass some configuration paramteters to seaborn so that the size you want is the default | call a method on the figure once it&#39;s been created | pass hight and aspect keywords to the seaborn plotting function | use the matplotlib.pyplot interface and call the figure() function | use the matplotlib.pyplot interface to get the current figure then set its size using a method | . each of which will work in some circumstances but not others! . Drawing a figure using pandas . Let&#39;s jump in. As an example we&#39;ll use the olympic medal dataset, which we can load directly from a URL:: . import pandas as pd data = pd.read_csv(&quot;https://raw.githubusercontent.com/mojones/binders/master/olympics.csv&quot;, sep=&quot; t&quot;) data . City Year Sport ... Medal Country Int Olympic Committee code . 0 Athens | 1896 | Aquatics | ... | Gold | Hungary | HUN | . 1 Athens | 1896 | Aquatics | ... | Silver | Austria | AUT | . 2 Athens | 1896 | Aquatics | ... | Bronze | Greece | GRE | . 3 Athens | 1896 | Aquatics | ... | Gold | Greece | GRE | . 4 Athens | 1896 | Aquatics | ... | Silver | Greece | GRE | . ... ... | ... | ... | ... | ... | ... | ... | . 29211 Beijing | 2008 | Wrestling | ... | Silver | Germany | GER | . 29212 Beijing | 2008 | Wrestling | ... | Bronze | Lithuania | LTU | . 29213 Beijing | 2008 | Wrestling | ... | Bronze | Armenia | ARM | . 29214 Beijing | 2008 | Wrestling | ... | Gold | Cuba | CUB | . 29215 Beijing | 2008 | Wrestling | ... | Silver | Russia | RUS | . 29216 rows × 12 columns . For our first figure, we&#39;ll count how many medals have been won in total by each country, then take the top thirty: . data[&#39;Country&#39;].value_counts().head(30) . United States 4335 Soviet Union 2049 United Kingdom 1594 France 1314 Italy 1228 ... Spain 377 Switzerland 376 Brazil 372 Bulgaria 331 Czechoslovakia 329 Name: Country, Length: 30, dtype: int64 . And turn it into a bar chart: . data[&#39;Country&#39;].value_counts().head(30).plot(kind=&#39;barh&#39;) . &lt;AxesSubplot:&gt; . Ignoring other asthetic aspects of the plot, it&#39;s obvious that we need to change the size - or rather the shape. Part of the confusion over sizes in plotting is that sometimes we need to just make the chart bigger or smaller, and sometimes we need to make it thinner or fatter. If we just scaled up this plot so that it was big enough to read the names on the vertical axis, then it would also be very wide. We can set the size by adding a figsize keyword argument to our pandas plot() function. The value has to be a tuple of sizes - it&#39;s actually the horizontal and vertical size in inches, but for most purposes we can think of them as arbirary units. . Here&#39;s what happens if we make the plot bigger, but keep the original shape: . data[&#39;Country&#39;].value_counts().head(30).plot(kind=&#39;barh&#39;, figsize=(20,10)) . &lt;AxesSubplot:&gt; . And here&#39;s a version that keeps the large vertical size but shrinks the chart horizontally so it doesn&#39;t take up so much space: . data[&#39;Country&#39;].value_counts().head(30).plot(kind=&#39;barh&#39;, figsize=(6,10)) . &lt;AxesSubplot:&gt; . Drawing a figure using matplotlib . OK, but what if we aren&#39;t using pandas&#39; convenient plot() method but drawing the chart using matplotlib directly? Let&#39;s look at the number of medals awarded in each year: . plt.plot(data[&#39;Year&#39;].value_counts().sort_index()) . [&lt;matplotlib.lines.Line2D at 0x7fb1bd16de20&gt;] . This time, we&#39;ll say that we want to make the plot longer in the horizontal direction, to better see the pattern over time. If we search the documentation for the matplotlib plot() funtion, we won&#39;t find any mention of size or shape. This actually makes sense in the design of matplotlib - plots don&#39;t really have a size, figures do. So to change it we have to call the figure() function: . import matplotlib.pyplot as plt plt.figure(figsize=(15,4)) plt.plot(data[&#39;Year&#39;].value_counts().sort_index()) . [&lt;matplotlib.lines.Line2D at 0x7fb1bd5f3dc0&gt;] . Notice that with the figure() function we have to call it before we make the call to plot(), otherwise it won&#39;t take effect: . plt.plot(data[&#39;Year&#39;].value_counts().sort_index()) # no effect, the plot has already been drawn plt.figure(figsize=(15,4)) . &lt;Figure size 1080x288 with 0 Axes&gt; . &lt;Figure size 1080x288 with 0 Axes&gt; . Drawing a figure with seaborn . OK, now what if we&#39;re using seaborn rather than matplotlib? Well, happily the same technique will work. We know from our first plot which countries have won the most medals overall, but now let&#39;s look at how this varies by year. We&#39;ll create a summary table to show the number of medals per year for all countries that have won at least 500 medals total. . (ignore this panda stuff if it seems confusing, and just look at the final table) . summary = ( data .groupby(&#39;Country&#39;) .filter(lambda x : len(x) &gt; 500) .groupby([&#39;Country&#39;, &#39;Year&#39;]) .size() .to_frame(&#39;medal count&#39;) .reset_index() ) # wrap long country names summary[&#39;Country&#39;] = summary[&#39;Country&#39;].str.replace(&#39; &#39;, &#39; n&#39;) summary . Country Year medal count . 0 Australia | 1896 | 2 | . 1 Australia | 1900 | 5 | . 2 Australia | 1920 | 6 | . 3 Australia | 1924 | 10 | . 4 Australia | 1928 | 4 | . ... ... | ... | ... | . 309 United nStates | 1992 | 224 | . 310 United nStates | 1996 | 260 | . 311 United nStates | 2000 | 248 | . 312 United nStates | 2004 | 264 | . 313 United nStates | 2008 | 315 | . 314 rows × 3 columns . Now we can do a box plot to show the distribution of yearly medal totals for each country: . import seaborn as sns sns.boxplot( data=summary, x=&#39;Country&#39;, y=&#39;medal count&#39;, color=&#39;red&#39;) . &lt;AxesSubplot:xlabel=&#39;Country&#39;, ylabel=&#39;medal count&#39;&gt; . This is hard to read because of all the names, so let&#39;s space them out a bit: . plt.figure(figsize=(20,5)) sns.boxplot( data=summary, x=&#39;Country&#39;, y=&#39;medal count&#39;, color=&#39;red&#39;) . &lt;AxesSubplot:xlabel=&#39;Country&#39;, ylabel=&#39;medal count&#39;&gt; . Now we come to the final complication; let&#39;s say we want to look at the distributions of the different medal types separately. We&#39;ll make a new summary table - again, ignore the pandas stuff if it&#39;s confusing, and just look at the final table: . summary_by_medal = ( data .groupby(&#39;Country&#39;) .filter(lambda x : len(x) &gt; 500) .groupby([&#39;Country&#39;, &#39;Year&#39;, &#39;Medal&#39;]) .size() .to_frame(&#39;medal count&#39;) .reset_index() ) summary_by_medal[&#39;Country&#39;] = summary_by_medal[&#39;Country&#39;].str.replace(&#39; &#39;, &#39; n&#39;) summary_by_medal . Country Year Medal medal count . 0 Australia | 1896 | Gold | 2 | . 1 Australia | 1900 | Bronze | 3 | . 2 Australia | 1900 | Gold | 2 | . 3 Australia | 1920 | Bronze | 1 | . 4 Australia | 1920 | Silver | 5 | . ... ... | ... | ... | ... | . 881 United nStates | 2004 | Gold | 116 | . 882 United nStates | 2004 | Silver | 75 | . 883 United nStates | 2008 | Bronze | 81 | . 884 United nStates | 2008 | Gold | 125 | . 885 United nStates | 2008 | Silver | 109 | . 886 rows × 4 columns . Now we will switch from boxplot() to the higher level catplot(), as this makes it easy to switch between different plot types. But notice that now our call to plt.figure() gets ignored: . plt.figure(figsize=(20,5)) sns.catplot( data=summary_by_medal, x=&#39;Country&#39;, y=&#39;medal count&#39;, hue=&#39;Medal&#39;, kind=&#39;box&#39; ) . &lt;seaborn.axisgrid.FacetGrid at 0x7fb1bcc23ac0&gt; . &lt;Figure size 1440x360 with 0 Axes&gt; . The reason for this is that the higher level plotting functions in seaborn (what the documentation calls Figure-level interfaces) have a different way of managing size, largely due to the fact that the often produce multiple subplots. To set the size when using catplot() or relplot() (also pairplot(), lmplot() and jointplot()), use the height keyword to control the size and the aspect keyword to control the shape: . sns.catplot( data=summary_by_medal, x=&#39;Country&#39;, y=&#39;medal count&#39;, hue=&#39;Medal&#39;, kind=&#39;box&#39;, height=5, # make the plot 5 units high aspect=3) # height should be three times width . &lt;seaborn.axisgrid.FacetGrid at 0x7fb1bc40d850&gt; . Because we often end up drawing small multiples with catplot() and relplot(), being able to control the shape separately from the size is very convenient. The height and aspect keywords apply to each subplot separately, not to the figure as a whole. So if we put each medal on a separate row rather than using hue, we&#39;ll end up with three subplots, so we&#39;ll want to set the height to be smaller, but the aspect ratio to be bigger: . sns.catplot( data=summary_by_medal, x=&#39;Country&#39;, y=&#39;medal count&#39;, row=&#39;Medal&#39;, kind=&#39;box&#39;, height=3, aspect=4, color=&#39;blue&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x7fb1bc04edf0&gt; . Printing a figure . Finally, a word about printing. If the reason that you need to change the size of a plot, rather than the shape, is because you need to print it, then don&#39;t worry about the size - get the shape that you want, then use savefig() to make the plot in SVG format: . plt.savefig(&#39;medals.svg&#39;) . &lt;Figure size 432x288 with 0 Axes&gt; . This will give you a plot in Scalable Vector Graphics format, which stores the actual lines and shapes of the chart so that you can print it at any size - even a giant poster - and it will look sharp. As a nice bonus, you can also edit individual bits of the chart using a graphical SVG editor (Inkscape is free and powerful, though takes a bit of effort to learn). .",
            "url": "https://mojones.github.io/dfd_jupyter_test/pandas/seaborn/matplotlib/visualization/2020/10/26/setting-figure-size-matplotlib-seaborn.html",
            "relUrl": "/pandas/seaborn/matplotlib/visualization/2020/10/26/setting-figure-size-matplotlib-seaborn.html",
            "date": " • Oct 26, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Rotating axis labels in matplotlib and seaborn",
            "content": "There&#39;s a common pattern which often occurs when working with charting libraries: drawing charts with all the defaults seems very straightforward, but when we want to change some aspect of the chart things get complicated. This pattern is even more noticable when working with a high-level library like seaborn - the library does all sorts of clever things to make our life easier, and lets us draw sophisticated, beautiful charts, so it&#39;s frustrating when we want to change something that feels like it should be simple. . In this article, we&#39;ll take a look at the classic example of this phenomenon - rotating axis tick labels. This seems like such a common thing that it should be easy, but it&#39;s one of the most commonly asked questions on StackOverflow for both seaborn and matplotlib. As an example dataset, we&#39;ll look at a table of Olympic medal winners. We can load it into pandas directly from a URL: . import pandas as pd data = pd.read_csv(&quot;https://raw.githubusercontent.com/mojones/binders/master/olympics.csv&quot;, sep=&quot; t&quot;) data . City Year Sport ... Medal Country Int Olympic Committee code . 0 Athens | 1896 | Aquatics | ... | Gold | Hungary | HUN | . 1 Athens | 1896 | Aquatics | ... | Silver | Austria | AUT | . 2 Athens | 1896 | Aquatics | ... | Bronze | Greece | GRE | . 3 Athens | 1896 | Aquatics | ... | Gold | Greece | GRE | . 4 Athens | 1896 | Aquatics | ... | Silver | Greece | GRE | . ... ... | ... | ... | ... | ... | ... | ... | . 29211 Beijing | 2008 | Wrestling | ... | Silver | Germany | GER | . 29212 Beijing | 2008 | Wrestling | ... | Bronze | Lithuania | LTU | . 29213 Beijing | 2008 | Wrestling | ... | Bronze | Armenia | ARM | . 29214 Beijing | 2008 | Wrestling | ... | Gold | Cuba | CUB | . 29215 Beijing | 2008 | Wrestling | ... | Silver | Russia | RUS | . 29216 rows × 12 columns . Each row is a single medal, and we have a bunch of different information like where and when the event took place, the classification of the event, and the name of the athlete that won. . We&#39;ll start with something simple; let&#39;s grab all the events for the 1980 games and see how many fall into each type of sport: . import seaborn as sns import matplotlib.pyplot as plt # set the figure size plt.figure(figsize=(10,5)) # draw the chart chart = sns.countplot( data=data[data[&#39;Year&#39;] == 1980], x=&#39;Sport&#39;, palette=&#39;Set1&#39; ) . Here we have the classic problem with categorical data: we need to display all the labels and because some of them are quite long, they overlap. How are we going to rotate them? The key is to look at what type of object we&#39;ve created. What is the type of the return value from the countplot() function, which we have stored in chart? . type(chart) . matplotlib.axes._subplots.AxesSubplot . Looks like chart is a matplotlib AxesSubplot object. This actually doesn&#39;t help us very much - if we go searching for the documentation for AxesSubplot we won&#39;t find anything useful. Instead, we have to know that an AxesSubplot is a type of Axes object, and now we can go look up the documentation for Axes in which we find the set_xticklabels() method. . Looking at the documentation for set_xticklabels() we don&#39;t actually see any obvious reference to rotation. The clue we&#39;re looking for is in the &quot;Other parameters&quot; section at the end, where it tells us that we can supply a list of keyword arguments that are properties of Text objects. . Finally, in the documentation for Text objects we can see a list of the properties, including rotation. This was a long journey! but hopefully it will pay off - there are lots of other useful properties here as well. Now we can finally set the rotation: . plt.figure(figsize=(10,5)) chart = sns.countplot( data=data[data[&#39;Year&#39;] == 1980], x=&#39;Sport&#39;, palette=&#39;Set1&#39; ) chart.set_xticklabels(rotation=45) . TypeError Traceback (most recent call last) &lt;ipython-input-27-059eaf6ffa77&gt; in &lt;module&gt; 5 palette=&#39;Set1&#39; 6 ) -&gt; 7 chart.set_xticklabels(rotation=45) ~/.virtualenvs/drawingfromdata/lib/python3.8/site-packages/matplotlib/axes/_base.py in wrapper(self, *args, **kwargs) 61 62 def wrapper(self, *args, **kwargs): &gt; 63 return get_method(self)(*args, **kwargs) 64 65 wrapper.__module__ = owner.__module__ ~/.virtualenvs/drawingfromdata/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs) 449 &#34;parameter will become keyword-only %(removal)s.&#34;, 450 name=name, obj_type=f&#34;parameter of {func.__name__}()&#34;) --&gt; 451 return func(*args, **kwargs) 452 453 return wrapper TypeError: _set_ticklabels() missing 1 required positional argument: &#39;labels&#39; . Disaster! We need to pass set_xticklabels() a list of the actual labels we want to use. Since we don&#39;t want to change the labels themselves, we can just call get_xticklabels(): . plt.figure(figsize=(10,5)) chart = sns.countplot( data=data[data[&#39;Year&#39;] == 1980], x=&#39;Sport&#39;, palette=&#39;Set1&#39; ) chart.set_xticklabels(chart.get_xticklabels(), rotation=45) None #don&#39;t show the label objects . This looks better, but notice how the &quot;Modern Pentathlon&quot; label is running into the &quot;Sailing&quot; label? That&#39;s because the labels have been rotated about their center - which also makes it hard to see which label belongs to which bar. We should also set the horizontal alignment to &quot;right&quot;: . plt.figure(figsize=(10,5)) chart = sns.countplot( data=data[data[&#39;Year&#39;] == 1980], x=&#39;Sport&#39;, palette=&#39;Set1&#39; ) chart.set_xticklabels(chart.get_xticklabels(), rotation=45, horizontalalignment=&#39;right&#39;) None #don&#39;t show the label objects . And just to show a few more things that we can do with set_xticklabels() we&#39;ll also set the font weight to be a bit lighter, and the font size to be a bit bigger: . plt.figure(figsize=(10,5)) chart = sns.countplot( data=data[data[&#39;Year&#39;] == 1980], x=&#39;Sport&#39;, palette=&#39;Set1&#39; ) chart.set_xticklabels( chart.get_xticklabels(), rotation=45, horizontalalignment=&#39;right&#39;, fontweight=&#39;light&#39;, fontsize=&#39;x-large&#39; ) None #don&#39;t show the label objects . In all of these examples, we&#39;ve been using the object-oriented interface to matplotlib - notice that we&#39;re calling set_xticklabels() directly on the chart object. . Another object is to use the pyplot interface. There&#39;s a method simply called xticks() which we could use like this: . import matplotlib.pyplot as plt plt.figure(figsize=(10,5)) chart = sns.countplot( data=data[data[&#39;Year&#39;] == 1980], x=&#39;Sport&#39;, palette=&#39;Set1&#39; ) plt.xticks( rotation=45, horizontalalignment=&#39;right&#39;, fontweight=&#39;light&#39;, fontsize=&#39;x-large&#39; ) None #don&#39;t show the label objects . Notice that when we do it this way the list of labels is optional, so we don&#39;t need to call get_xticklabels(). . Althought the pyplot interface is easier to use in this case, in general I find it clearer to use the object-oriented interface, as it tends to be more explicit. . Everything that we&#39;ve seen above applies if we&#39;re using matplotlib directly instead of seaborn: once we have an Axes object, we can call set_xticklabels() on it. Let&#39;s do the same thing using pandas&#39;s built in plotting function: . chart = data[data[&#39;Year&#39;] == 1980][&#39;Sport&#39;].value_counts().plot(kind=&#39;bar&#39;) chart.set_xticklabels(chart.get_xticklabels(), rotation=45, horizontalalignment=&#39;right&#39;) None . Dealing with multiple plots . Let&#39;s try another plot. One of the great features of seaborn is that it makes it very easy to draw multiple plots. Let&#39;s see how the distribution of medals in each sport changed between 1980 and 2008: . chart = sns.catplot( data=data[data[&#39;Year&#39;].isin([1980, 2008])], x=&#39;Sport&#39;, kind=&#39;count&#39;, palette=&#39;Set1&#39;, row=&#39;Year&#39;, aspect=3, height=3 ) . As before, the labels need to be rotated. Let&#39;s try the approach that we used before: . chart = sns.catplot( data=data[data[&#39;Year&#39;].isin([1980, 2008])], x=&#39;Sport&#39;, kind=&#39;count&#39;, palette=&#39;Set1&#39;, row=&#39;Year&#39;, aspect=3, height=3 ) chart.set_xticklabels(chart.get_xticklabels(), rotation=45, horizontalalignment=&#39;right&#39;) . AttributeError Traceback (most recent call last) &lt;ipython-input-8-69ed9d536d8c&gt; in &lt;module&gt; 8 height=3 9 ) &gt; 10 chart.set_xticklabels(chart.get_xticklabels(), rotation=45, horizontalalignment=&#39;right&#39;) AttributeError: &#39;FacetGrid&#39; object has no attribute &#39;get_xticklabels&#39; . We run into an error. Note that the missing attribute is not set_xticklabels() but get_xticklabels(). The reason why this approach worked for countplot() and not for factorplot() is that the output from countplot() is a single Axes object, as we saw above, but the output from factorplot() is a seaborn FacetGrid object: . type(chart) . seaborn.axisgrid.FacetGrid . whose job is to store a collection of multiple axes - two in this case. So how to rotate the labels? It turns out that FacetGrid has its own version of set_xticklabels that will take care of things: . chart = sns.catplot( data=data[data[&#39;Year&#39;].isin([1980, 2008])], x=&#39;Sport&#39;, kind=&#39;count&#39;, palette=&#39;Set1&#39;, row=&#39;Year&#39;, aspect=3, height=3 ) chart.set_xticklabels(rotation=65, horizontalalignment=&#39;right&#39;) None . The pyplot interface that we saw earlier also works fine: . chart = sns.catplot( data=data[data[&#39;Year&#39;].isin([1980, 2008])], x=&#39;Sport&#39;, kind=&#39;count&#39;, palette=&#39;Set1&#39;, row=&#39;Year&#39;, aspect=3, height=3 ) plt.xticks(rotation=65, horizontalalignment=&#39;right&#39;) None . And, of course, everything that we&#39;ve done here will work for y-axis labels as well - we typically don&#39;t need to change their rotation, but we might want to set their other properties. As an example, let&#39;s count how many medals were won at each Olypmic games for each country in each year. To keep the dataset managable, we&#39;ll just look at countries that have won more than 500 metals in total: . by_sport = (data .groupby(&#39;Country&#39;) .filter(lambda x : len(x) &gt; 500) .groupby([&#39;Country&#39;, &#39;Year&#39;]) .size() .unstack() ) by_sport . Year 1896 1900 1904 ... 2000 2004 2008 . Country . Australia 2.0 | 5.0 | NaN | ... | 183.0 | 157.0 | 149.0 | . Canada NaN | 2.0 | 35.0 | ... | 31.0 | 17.0 | 34.0 | . China NaN | NaN | NaN | ... | 79.0 | 94.0 | 184.0 | . East Germany NaN | NaN | NaN | ... | NaN | NaN | NaN | . France 11.0 | 185.0 | NaN | ... | 66.0 | 53.0 | 76.0 | . ... ... | ... | ... | ... | ... | ... | ... | . Russia NaN | NaN | NaN | ... | 188.0 | 192.0 | 143.0 | . Soviet Union NaN | NaN | NaN | ... | NaN | NaN | NaN | . Sweden NaN | 1.0 | NaN | ... | 32.0 | 12.0 | 7.0 | . United Kingdom 7.0 | 78.0 | 2.0 | ... | 55.0 | 57.0 | 77.0 | . United States 20.0 | 55.0 | 394.0 | ... | 248.0 | 264.0 | 315.0 | . 17 rows × 26 columns . If the use of two groupby() method calls is confusing, take a look at this article on grouping. The first one just gives us the rows belonging to countries that have won more than 500 medals; the second one does the aggregation and fills in missing data. The natural way to display a table like this is as a heatmap: . plt.figure(figsize=(10,10)) g = sns.heatmap( by_sport, square=True, # make cells square cbar_kws={&#39;fraction&#39; : 0.01}, # shrink colour bar cmap=&#39;OrRd&#39;, # use orange/red colour map linewidth=1 # space between cells ) . This example is perfectly readable, but by way of an example we&#39;ll rotate both the x and y axis labels: . plt.figure(figsize=(10,10)) g = sns.heatmap( by_sport, square=True, cbar_kws={&#39;fraction&#39; : 0.01}, cmap=&#39;OrRd&#39;, linewidth=1 ) g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment=&#39;right&#39;) g.set_yticklabels(g.get_yticklabels(), rotation=45, horizontalalignment=&#39;right&#39;) None # prevent the list of label objects showing up annoyingly in the output . OK, I think that covers it. That was an agonizingly long article to read just about rotating labels, but hopefully it&#39;s given you an insight into what&#39;s going on. It all comes down to understanding what type of object you&#39;re working with - an Axes, a FacetGrid, or a PairGrid. . If you encounter a situation where none of these work, drop me an email at martin@drawingwithdata.com and I&#39;ll update this article! .",
            "url": "https://mojones.github.io/dfd_jupyter_test/seaborn/matplotlib/visualization/2020/10/26/rotate-axis-labels-matplotlib-seaborn.html",
            "relUrl": "/seaborn/matplotlib/visualization/2020/10/26/rotate-axis-labels-matplotlib-seaborn.html",
            "date": " • Oct 26, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "When to use aggreagate/filter/transform with pandas",
            "content": "I&#39;ve been teaching quite a lot of Pandas recently, and a lot of the recurring questions are about grouping. That&#39;s no surprise, as it&#39;s one of the most flexible features of Pandas. However, that flexibility also makes it sometimes confusing. . I think that most of the confusion arises because the same grouping logic is used for (at least) three distinct operations in Pandas. In the order that we normally learn them, these are: . calculating some aggregate measurement for each group (size, mean, etc.) | filtering the rows on a property of the group they belong to | calculating a new value for each row based on a property of the group. | . This leads commonly to situations where we know that we need to use groupby() - and may even be able to easily figure out what the arguments to groupby() should be - but are unsure about what to do next. . Here&#39;s a trick that I&#39;ve found useful when teaching these ideas: think about the result you want, and work back from there. If you want to get a single value for each group, use aggregate() (or one of its shortcuts). If you want to get a subset of the original rows, use filter(). And if you want to get a new value for each original row, use transpose(). . Here&#39;s a minimal example of the three different situations, all of which require exactly the same call to groupby() but which do different things with the result. We&#39;ll use the well known tips dataset which we can load directly from the web: . import pandas as pd df = pd.read_csv(&quot;https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv&quot;) pd.options.display.max_rows = 10 df . total_bill tip sex smoker day time size . 0 16.99 | 1.01 | Female | No | Sun | Dinner | 2 | . 1 10.34 | 1.66 | Male | No | Sun | Dinner | 3 | . 2 21.01 | 3.50 | Male | No | Sun | Dinner | 3 | . 3 23.68 | 3.31 | Male | No | Sun | Dinner | 2 | . 4 24.59 | 3.61 | Female | No | Sun | Dinner | 4 | . ... ... | ... | ... | ... | ... | ... | ... | . 239 29.03 | 5.92 | Male | No | Sat | Dinner | 3 | . 240 27.18 | 2.00 | Female | Yes | Sat | Dinner | 2 | . 241 22.67 | 2.00 | Male | Yes | Sat | Dinner | 2 | . 242 17.82 | 1.75 | Male | No | Sat | Dinner | 2 | . 243 18.78 | 3.00 | Female | No | Thur | Dinner | 2 | . 244 rows × 7 columns . If you&#39;re not familiar with this dataset, all you need to know is that each row represents a meal at a restaurant, and the columns store the value of the total bill and the tip, plus some metadata about the customer - their sex, whether or not they were a smoker, what day and time they ate at, and the size of their party. Also, notice that we have 244 rows - this will be important later on. . What was the average total bill on each day? . To answer this, let&#39;s imagine that we have already figured out that we need to group by day: . df.groupby(&#39;day&#39;) . now what&#39;s the next step? Use the trick that I just described and start by imagining what we want the output to look like. We want a single value for each group, so we need to use aggregate(): . df.groupby(&#39;day&#39;).aggregate(&#39;mean&#39;) . total_bill tip size . day . Fri 17.151579 | 2.734737 | 2.105263 | . Sat 20.441379 | 2.993103 | 2.517241 | . Sun 21.410000 | 3.255132 | 2.842105 | . Thur 17.682742 | 2.771452 | 2.451613 | . We&#39;re only interested in the total_bill column, so we can select it (either before or after we do the aggregation): . df.groupby(&#39;day&#39;)[&#39;total_bill&#39;].aggregate(&#39;mean&#39;) . day Fri 17.151579 Sat 20.441379 Sun 21.410000 Thur 17.682742 Name: total_bill, dtype: float64 . Pandas has lots of shortcuts for the various ways to aggregate group values - we could use mean() here instead: . df.groupby(&#39;day&#39;)[&#39;total_bill&#39;].mean() . day Fri 17.151579 Sat 20.441379 Sun 21.410000 Thur 17.682742 Name: total_bill, dtype: float64 . Which meals were eaten on days where the average bill was greater than 20? . For this question, think again about the output we want - our goal here is to get a subset of the original rows, so this is a job for filter(). The argument to filter() must be a function or lambda that will take a group and return True or False to determine whether rows belonging to that group should be included in the output. Here&#39;s how we might do it with a lambda: . df.groupby(&#39;day&#39;).filter(lambda x : x[&#39;total_bill&#39;].mean() &gt; 20) . total_bill tip sex smoker day time size . 0 16.99 | 1.01 | Female | No | Sun | Dinner | 2 | . 1 10.34 | 1.66 | Male | No | Sun | Dinner | 3 | . 2 21.01 | 3.50 | Male | No | Sun | Dinner | 3 | . 3 23.68 | 3.31 | Male | No | Sun | Dinner | 2 | . 4 24.59 | 3.61 | Female | No | Sun | Dinner | 4 | . ... ... | ... | ... | ... | ... | ... | ... | . 238 35.83 | 4.67 | Female | No | Sat | Dinner | 3 | . 239 29.03 | 5.92 | Male | No | Sat | Dinner | 3 | . 240 27.18 | 2.00 | Female | Yes | Sat | Dinner | 2 | . 241 22.67 | 2.00 | Male | Yes | Sat | Dinner | 2 | . 242 17.82 | 1.75 | Male | No | Sat | Dinner | 2 | . 163 rows × 7 columns . Notice that our output dataframe has only 163 rows (compared to the 244 that we started with), and that the columns are exactly the same as the input. . Compared to our first example, it&#39;s a bit harder to see why this is useful - typically we&#39;ll do a filter like this and then follow it up with another operation. For example, we might want to compare the average party size on days where the average bill is high: . # surrounding parens let us split the different parts of the expression # over multiple lines ( df .groupby(&#39;day&#39;) .filter( lambda x : x[&#39;total_bill&#39;].mean() &gt; 20) [&#39;size&#39;] .mean() ) . 2.668711656441718 . with the average party size on days where the average bill is low: . ( df .groupby(&#39;day&#39;) .filter(lambda x : x[&#39;total_bill&#39;].mean() &lt;= 20) [&#39;size&#39;] .mean() ) . 2.3703703703703702 . Incidentally, a question that I&#39;m often asked is what the type of the argument to the lambda is - what actually is the variable x in our examples above? We can find out by passing a lambda that just prints the type of its input: . df.groupby(&#39;day&#39;).filter(lambda x: print(type(x))) . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; . total_bill tip sex smoker day time size . And we see that each group is passed to our lambda function as a Pandas DataFrame, so we already know how to use it. . How did the cost of each meal compare to the average for the day? . This last example is the trickiest to understand, but remember our trick - start by thinking about the desired output. In this case we are trying to generate a new value for each input row - the total bill divided by the average total bill for each day. (If you have a scientific or maths background then you might think of this as a normalized or scaled total bill). To make a new value for each row, we use transform(). . To start with, let&#39;s see what happens when we pass in a lambda to transform() that just gives us the mean of its input: . df.groupby(&#39;day&#39;).transform(lambda x : x.mean()) . total_bill tip size . 0 21.410000 | 3.255132 | 2.842105 | . 1 21.410000 | 3.255132 | 2.842105 | . 2 21.410000 | 3.255132 | 2.842105 | . 3 21.410000 | 3.255132 | 2.842105 | . 4 21.410000 | 3.255132 | 2.842105 | . ... ... | ... | ... | . 239 20.441379 | 2.993103 | 2.517241 | . 240 20.441379 | 2.993103 | 2.517241 | . 241 20.441379 | 2.993103 | 2.517241 | . 242 20.441379 | 2.993103 | 2.517241 | . 243 17.682742 | 2.771452 | 2.451613 | . 244 rows × 3 columns . Notice that we get the same number of output rows as input rows - Pandas has calculated the mean for each group, then used the results as the new values for each row. We&#39;re only interested in the total bill, so let&#39;s get rid of the other columns: . df.groupby(&#39;day&#39;)[&#39;total_bill&#39;].transform(lambda x : x.mean()) . 0 21.410000 1 21.410000 2 21.410000 3 21.410000 4 21.410000 ... 239 20.441379 240 20.441379 241 20.441379 242 20.441379 243 17.682742 Name: total_bill, Length: 244, dtype: float64 . This gives us a series with the same number of rows as our input data. We could assign this to a new column in our dataframe: . df[&#39;day_average&#39;] = df.groupby(&#39;day&#39;)[&#39;total_bill&#39;].transform(lambda x : x.mean()) df . total_bill tip sex smoker day time size day_average . 0 16.99 | 1.01 | Female | No | Sun | Dinner | 2 | 21.410000 | . 1 10.34 | 1.66 | Male | No | Sun | Dinner | 3 | 21.410000 | . 2 21.01 | 3.50 | Male | No | Sun | Dinner | 3 | 21.410000 | . 3 23.68 | 3.31 | Male | No | Sun | Dinner | 2 | 21.410000 | . 4 24.59 | 3.61 | Female | No | Sun | Dinner | 4 | 21.410000 | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 239 29.03 | 5.92 | Male | No | Sat | Dinner | 3 | 20.441379 | . 240 27.18 | 2.00 | Female | Yes | Sat | Dinner | 2 | 20.441379 | . 241 22.67 | 2.00 | Male | Yes | Sat | Dinner | 2 | 20.441379 | . 242 17.82 | 1.75 | Male | No | Sat | Dinner | 2 | 20.441379 | . 243 18.78 | 3.00 | Female | No | Thur | Dinner | 2 | 17.682742 | . 244 rows × 8 columns . Which would allow us to calculate the scaled total bills: . df[&#39;total_bill&#39;] / df[&#39;day_average&#39;] . 0 0.793554 1 0.482952 2 0.981317 3 1.106025 4 1.148529 ... 239 1.420159 240 1.329656 241 1.109025 242 0.871761 243 1.062052 Length: 244, dtype: float64 . But we could also calculate the scaled bill as part of the transform: . df[&#39;scaled bill&#39;] = df.groupby(&#39;day&#39;)[&#39;total_bill&#39;].transform(lambda x : x/x.mean()) df.head() . total_bill tip sex smoker day time size day_average scaled bill . 0 16.99 | 1.01 | Female | No | Sun | Dinner | 2 | 21.41 | 0.793554 | . 1 10.34 | 1.66 | Male | No | Sun | Dinner | 3 | 21.41 | 0.482952 | . 2 21.01 | 3.50 | Male | No | Sun | Dinner | 3 | 21.41 | 0.981317 | . 3 23.68 | 3.31 | Male | No | Sun | Dinner | 2 | 21.41 | 1.106025 | . 4 24.59 | 3.61 | Female | No | Sun | Dinner | 4 | 21.41 | 1.148529 | . In conclusion . All of our three examples used exactly the same groupby() call to begin with: . df.groupby(&#39;day&#39;)[&#39;total_bill&#39;].mean() df.groupby(&#39;day&#39;).filter(lambda x : x[&#39;total_bill&#39;].mean() &gt; 20) df.groupby(&#39;day&#39;)[&#39;total_bill&#39;].transform(lambda x : x/x.mean()) . but by doing different things with the resulting groups we get very different outputs. To reiterate: . if we want to get a single value for each group -&gt; use aggregate() | if we want to get a subset of the input rows -&gt; use filter() | if we want to get a new value for each input row -&gt; use transform() | .",
            "url": "https://mojones.github.io/dfd_jupyter_test/pandas/grouping/2020/10/26/pandas-groupby-transform-aggregate-filter.html",
            "relUrl": "/pandas/grouping/2020/10/26/pandas-groupby-transform-aggregate-filter.html",
            "date": " • Oct 26, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Making a pairwise distance matrix in pandas",
            "content": "This is a somewhat specialized problem that forms part of a lot of data science and clustering workflows. It starts with a relatively straightforward question: if we have a bunch of measurements for two different things, how do we come up with a single number that represents the difference between the two things? . An example will make the question clearer. Let&#39;s load our olympic medal dataset: . import pandas as pd data = pd.read_csv(&quot;https://raw.githubusercontent.com/mojones/binders/master/olympics.csv&quot;, sep=&quot; t&quot;) data . City Year Sport ... Medal Country Int Olympic Committee code . 0 Athens | 1896 | Aquatics | ... | Gold | Hungary | HUN | . 1 Athens | 1896 | Aquatics | ... | Silver | Austria | AUT | . 2 Athens | 1896 | Aquatics | ... | Bronze | Greece | GRE | . 3 Athens | 1896 | Aquatics | ... | Gold | Greece | GRE | . 4 Athens | 1896 | Aquatics | ... | Silver | Greece | GRE | . ... ... | ... | ... | ... | ... | ... | ... | . 29211 Beijing | 2008 | Wrestling | ... | Silver | Germany | GER | . 29212 Beijing | 2008 | Wrestling | ... | Bronze | Lithuania | LTU | . 29213 Beijing | 2008 | Wrestling | ... | Bronze | Armenia | ARM | . 29214 Beijing | 2008 | Wrestling | ... | Gold | Cuba | CUB | . 29215 Beijing | 2008 | Wrestling | ... | Silver | Russia | RUS | . 29216 rows × 12 columns . and measure, for each different country, the number of medals they&#39;ve won in each different sport: . summary = data.groupby([&#39;Country&#39;, &#39;Sport&#39;]).size().unstack().fillna(0) summary . Sport Aquatics Archery Athletics ... Water Motorsports Weightlifting Wrestling . Country . Afghanistan 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | . Algeria 0.0 | 0.0 | 6.0 | ... | 0.0 | 0.0 | 0.0 | . Argentina 3.0 | 0.0 | 5.0 | ... | 0.0 | 2.0 | 0.0 | . Armenia 0.0 | 0.0 | 0.0 | ... | 0.0 | 4.0 | 4.0 | . Australasia 11.0 | 0.0 | 1.0 | ... | 0.0 | 0.0 | 0.0 | . ... ... | ... | ... | ... | ... | ... | ... | . Virgin Islands* 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | . West Germany 62.0 | 0.0 | 67.0 | ... | 0.0 | 7.0 | 9.0 | . Yugoslavia 91.0 | 0.0 | 2.0 | ... | 0.0 | 0.0 | 16.0 | . Zambia 0.0 | 0.0 | 1.0 | ... | 0.0 | 0.0 | 0.0 | . Zimbabwe 7.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | . 137 rows × 42 columns . Now we&#39;ll pick two countries: . summary.loc[[&#39;Germany&#39;, &#39;Italy&#39;]] . Sport Aquatics Archery Athletics ... Water Motorsports Weightlifting Wrestling . Country . Germany 175.0 | 6.0 | 99.0 | ... | 0.0 | 20.0 | 24.0 | . Italy 113.0 | 12.0 | 71.0 | ... | 0.0 | 14.0 | 20.0 | . 2 rows × 42 columns . Each country has 44 columns giving the total number of medals won in each sport. Our job is to come up with a single number that summarizes how different those two lists of numbers are. Mathematicians have figured out lots of different ways of doing that, many of which are implemented in the scipy.spatial.distance module. . If we just import pdist from the module, and pass in our dataframe of two countries, we&#39;ll get a measuremnt: . from scipy.spatial.distance import pdist pdist(summary.loc[[&#39;Germany&#39;, &#39;Italy&#39;]]) . array([342.3024978]) . That&#39;s the distance score using the default metric, which is called the euclidian distance. Think of it as the straight line distance between the two points in space defined by the two lists of 44 numbers. . Now, what happens if we pass in a dataframe with three countries? . pdist(summary.loc[[&#39;Germany&#39;, &#39;Italy&#39;, &#39;France&#39;]]) . array([342.3024978 , 317.98584874, 144.82403116]) . As we might expect, we have three measurements: . Germany and Italy | Germnay and France | Italy and France | . But it&#39;s not easy to figure out which belongs to which. Happily, scipy also has a helper function that will take this list of numbers and turn it back into a square matrix: . from scipy.spatial.distance import squareform squareform(pdist(summary.loc[[&#39;Germany&#39;, &#39;Italy&#39;, &#39;France&#39;]])) . array([[ 0. , 342.3024978 , 317.98584874], [342.3024978 , 0. , 144.82403116], [317.98584874, 144.82403116, 0. ]]) . In order to make sense of this, we need to re-attach the country names, which we can just do by turning it into a DataFrame: . pd.DataFrame( squareform(pdist(summary.loc[[&#39;Germany&#39;, &#39;Italy&#39;, &#39;France&#39;]])), columns = [&#39;Germany&#39;, &#39;Italy&#39;, &#39;France&#39;], index = [&#39;Germany&#39;, &#39;Italy&#39;, &#39;France&#39;] ) . Germany Italy France . Germany 0.000000 | 342.302498 | 317.985849 | . Italy 342.302498 | 0.000000 | 144.824031 | . France 317.985849 | 144.824031 | 0.000000 | . Hopefully this agrees with our intuition; the numbers on the diagonal are all zero, because each country is identical to itself, and the numbers above and below are mirror images, because the distance between Germany and France is the same as the distance between France and Germany (remember that we are talking about distance in terms of their medal totals, not geographical distance!) . Finally, to get pairwise measurements for the whole input dataframe, we just pass in the complete object and get the country names from the index: . pairwise = pd.DataFrame( squareform(pdist(summary)), columns = summary.index, index = summary.index ) pairwise . Country Afghanistan Algeria Argentina ... Yugoslavia Zambia Zimbabwe . Country . Afghanistan 0.000000 | 8.774964 | 96.643675 | ... | 171.947666 | 1.732051 | 17.492856 | . Algeria 8.774964 | 0.000000 | 95.199790 | ... | 171.688672 | 7.348469 | 19.519221 | . Argentina 96.643675 | 95.199790 | 0.000000 | ... | 148.128323 | 96.348326 | 89.810912 | . Armenia 5.830952 | 9.848858 | 96.477977 | ... | 171.604196 | 5.744563 | 18.384776 | . Australasia 18.708287 | 20.024984 | 97.744565 | ... | 166.991018 | 18.627936 | 22.360680 | . ... ... | ... | ... | ... | ... | ... | ... | . Virgin Islands* 1.414214 | 8.774964 | 96.457244 | ... | 171.947666 | 1.732051 | 17.492856 | . West Germany 153.052279 | 150.306354 | 142.537714 | ... | 184.945938 | 152.577849 | 144.045132 | . Yugoslavia 171.947666 | 171.688672 | 148.128323 | ... | 0.000000 | 171.874955 | 169.103519 | . Zambia 1.732051 | 7.348469 | 96.348326 | ... | 171.874955 | 0.000000 | 17.521415 | . Zimbabwe 17.492856 | 19.519221 | 89.810912 | ... | 169.103519 | 17.521415 | 0.000000 | . 137 rows × 137 columns . A nice way to visualize these is with a heatmap. 137 countries is a bit too much to show on a webpage, so let&#39;s restrict it to just the countries that have scored at least 500 medals total: . import seaborn as sns import matplotlib.pyplot as plt # make summary table for just top countries top_countries = ( data .groupby(&#39;Country&#39;) .filter(lambda x : len(x) &gt; 500) .groupby([&#39;Country&#39;, &#39;Sport&#39;]) .size() .unstack() .fillna(0) ) # make pairwise distance matrix pairwise_top = pd.DataFrame( squareform(pdist(top_countries)), columns = top_countries.index, index = top_countries.index ) # plot it with seaborn plt.figure(figsize=(10,10)) sns.heatmap( pairwise_top, cmap=&#39;OrRd&#39;, linewidth=1 ) . &lt;AxesSubplot:xlabel=&#39;Country&#39;, ylabel=&#39;Country&#39;&gt; . Now that we have a plot to look at, we can see a problem with the distance metric we&#39;re using. The US has won so many more medals than other countries that it distorts the measurement. And if we think about it, what we&#39;re really interested in is not the exact number of medals in each category, but the relative number. In other words, we want two contries to be considered similar if they both have about twice as many medals in boxing as athletics, for example, regardless of the exact numbers. . Luckily for us, there is a distance measure already implemented in scipy that has that property - it&#39;s called cosine distance. Think of it as a measurement that only looks at the relationships between the 44 numbers for each country, not their magnitude. We can switch to cosine distance by specifying the metric keyword argument in pdist: . pairwise_top = pd.DataFrame( squareform(pdist(top_countries, metric=&#39;cosine&#39;)), columns = top_countries.index, index = top_countries.index ) # plot it with seaborn plt.figure(figsize=(10,10)) sns.heatmap( pairwise_top, cmap=&#39;OrRd&#39;, linewidth=1 ) . &lt;AxesSubplot:xlabel=&#39;Country&#39;, ylabel=&#39;Country&#39;&gt; . And as you can see we spot some much more interstesting patterns. Notice, for example, that Russia and Soviet Union have a very low distance (i.e. their medal distributions are very similar). . When looking at data like this, remember that the shade of each cell is not telling us anything about how many medals a country has won - simply how different or similar each country is to each other. Compare the above heatmap with this one which displays the proportion of medals in each sport per country: . plt.figure(figsize=(10,10)) sns.heatmap( top_countries.apply(lambda x : x / x.sum(), axis=1), cmap=&#39;BuPu&#39;, square=True, cbar_kws = {&#39;fraction&#39; : 0.02} ) . &lt;AxesSubplot:xlabel=&#39;Sport&#39;, ylabel=&#39;Country&#39;&gt; . Finally, how might we find pairs of countries that have very similar medal distributions (i.e. very low numbers in the pairwise table)? By far the easiest way is to start of by reshaping the table into long form, so that each comparison is on a separate row: . pairwise = pd.DataFrame( squareform(pdist(summary, metric=&#39;cosine&#39;)), columns = summary.index, index = summary.index ) # move to long form long_form = pairwise.unstack() # rename columns and turn into a dataframe long_form.index.rename([&#39;Country A&#39;, &#39;Country B&#39;], inplace=True) long_form = long_form.to_frame(&#39;cosine distance&#39;).reset_index() . Now we can write our filter as normal, remembering to filter out the unintersting rows that tell us a country&#39;s distance from itself! . long_form[ (long_form[&#39;cosine distance&#39;] &lt; 0.05) &amp; (long_form[&#39;Country A&#39;] != long_form[&#39;Country B&#39;]) ] . Country A Country B cosine distance . 272 Algeria | Zambia | 0.026671 | . 1034 Azerbaijan | Mongolia | 0.045618 | . 1105 Bahamas | Barbados | 0.021450 | . 1111 Bahamas | British West Indies | 0.021450 | . 1113 Bahamas | Burundi | 0.021450 | . ... ... | ... | ... | . 17033 United Arab Emirates | Haiti | 0.010051 | . 17037 United Arab Emirates | Independent Olympic Participants | 0.000000 | . 17051 United Arab Emirates | Kuwait | 0.000000 | . 18164 Virgin Islands* | Netherlands Antilles* | 0.000000 | . 18496 Zambia | Algeria | 0.026671 | . 462 rows × 3 columns .",
            "url": "https://mojones.github.io/dfd_jupyter_test/pandas/clustering/2020/10/26/making-a-pairwise-distance-matrix-in-pandas.html",
            "relUrl": "/pandas/clustering/2020/10/26/making-a-pairwise-distance-matrix-in-pandas.html",
            "date": " • Oct 26, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://mojones.github.io/dfd_jupyter_test/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Drawing from Data book",
          "content": ". Time to get to grips with your data . With Python, pandas and seaborn in your toolbox, you too can develop data exploration superpowers. .",
          "url": "https://mojones.github.io/dfd_jupyter_test/book/",
          "relUrl": "/book/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://mojones.github.io/dfd_jupyter_test/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}